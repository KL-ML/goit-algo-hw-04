## goit-algo-hw-04
# Набори даних:
Генеруємо задану кількість унікальних елементів.
Використаємо 4 набори даних з: 100, 1000, 10000, 100000 елементів 

# Заміри:
| Алгоритм        | 100                   | 1000            | 10000          | 100000        |
|-----------------|-----------------------|-----------------|----------------|---------------|
| Timsort(sorted) | 3.374973312020302e-05 | 0.000256499741  | 0.00282904179  | 0.0349202076  |
| Timsort(sort)   | 2.10409052670002e-05  | 0.000248833093  | 0.00274629099  | 0.0325563331  |
| Merge           | 8.962489664554596e-05 | 0.001150832977  | 0.01475587487  | 0.1842314577  |
| Insertion       | 0.000117457937449     | 0.012400874868  | 1.32119662501  | 134.32850087  |

# Аналіз
Поглянувши на заміри часу виконання сортування, представлені в таблиці, можемо наочно переконатися, що `Timsort` (обидві вбудовані функції сортування: sorted і sort) є найшвидшим алгоритмом серед порвінюваних і демонструють мінімальний час обробки для будь-яких обсягів даних.

Оцінюючи продуктивність зі зростанням даних, бачимо, що час обробки алгоритму Insertion Sort збільшується значно швидше в порівнянні з Merge Sort.

При аналізі великих даних (10 000 записів) найгірші показники часу обробки має Insertion Sort, що робить його недоцільним для застосування на великих масивах через його квадратичну складність. У той же час, Merge Sort показав кращі результати на великих обсягах даних.

# Висновок
Можемо зробити висновок, що при необхідності сортування великих масивів даних слід обирати алгоритми з часом виконання лінійно-логарифмічним (O(n log n)), як-от Merge Sort. Для менших масивів можна застосовувати простіші методи, такі як Insertion Sort, але варто бути уважним до їх обмеженої продуктивності на великих обсягах даних. 
Але, як бачимо, Timsort та Timsorted є абсолютними переможцями по швидкості виконання для наборів данних будь-якої складності, тому розробникам на мові python немає дожного сенсу писати власні алгоритми сортування.
